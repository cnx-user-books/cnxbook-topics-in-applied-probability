<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:md="http://cnx.rice.edu/mdml">
  <title>Markov Decision -- Type 3 Gains</title>
  <metadata>
  <md:content-id>m31065</md:content-id><md:title>Markov Decision -- Type 3 Gains</md:title>
  <md:abstract/>
  <md:uuid>ad43bb4e-190a-4edc-830b-89a5caa606f5</md:uuid>
</metadata>
<featured-links>
  <!-- WARNING! The 'featured-links' section is read only. Do not edit below.
       Changes to the links section in the source will not be saved. -->
    <link-group type="supplemental">
      <link url="m-file directory.zip" strength="3">Basic M-Procedures for Calculation</link>
    </link-group>
  <!-- WARNING! The 'featured-links' section is read only. Do not edit above.
       Changes to the links section in the source will not be saved. -->
</featured-links>
<content>
    <example id="fs-id8473464">
    <!--empty paragraphs get left behind.-->
    <para id="id310104">An electronic store stocks a certain type of VCR.   At the end of each week,
an order is placed for early delivery the following Monday.   A maximum of four
units is stocked.   Let the states be the number of units on hand at the end
of the sales week: <m:math overflow="scroll"><m:mrow><m:mspace width="4pt"/><m:mi>E</m:mi><m:mi>b</m:mi><m:mo>=</m:mo><m:mo>{</m:mo><m:mn>0</m:mn><m:mo>,</m:mo><m:mspace width="0.166667em"/><m:mn>1</m:mn><m:mo>,</m:mo><m:mspace width="0.166667em"/><m:mn>2</m:mn><m:mo>,</m:mo><m:mspace width="0.166667em"/><m:mn>3</m:mn><m:mo>,</m:mo><m:mspace width="0.166667em"/><m:mn>4</m:mn><m:mo>}</m:mo><m:mspace width="4pt"/></m:mrow></m:math>.   Two possible actions:</para>
    <!--empty paragraphs get left behind.-->
    <list id="id310174" display="block" list-type="bulleted">
      <item id="uid1">Order two units, at a cost of $150 each
</item>
      <item id="uid2">Order four units, at a cost of $120 each

</item>
    </list>
    <para id="id310205">Units sell for $200. If demand exceeds the stock in hand, the retailer assumes
a penalty of $40 per unit (in losses due to customer dissatisfaction, etc.).   
Because of turnover, return on sales is considered two percent per week, so
that discount is <m:math overflow="scroll"><m:mrow><m:mi>α</m:mi><m:mo>=</m:mo><m:mn>1</m:mn><m:mo>/</m:mo><m:mn>1</m:mn><m:mo>.</m:mo><m:mn>02</m:mn></m:mrow></m:math> on a weekly basis.</para>
    <!--empty paragraphs get left behind.-->
    <para id="id310238">In state 0, there are three possible actions: order 0, 2, or   4.   In states 1 and 2
there are two possible actions:   order 0 or 2.   In states 3 and 4, the only action
is to order 0.   Customer demand in week <m:math overflow="scroll"><m:mrow><m:mi>n</m:mi><m:mo>+</m:mo><m:mn>1</m:mn></m:mrow></m:math> is represented by a random variable
<m:math overflow="scroll"><m:msub><m:mi>D</m:mi><m:mrow><m:mi>n</m:mi><m:mo>+</m:mo><m:mn>1</m:mn></m:mrow></m:msub></m:math>.   The class is iid, uniformly distributed on the values 0, 1, 2, 3, 4.   
If <emphasis effect="italics">X<sub>n</sub></emphasis> is the state at the end of week <emphasis effect="italics">n</emphasis>, then <m:math overflow="scroll"><m:mrow><m:mo>{</m:mo><m:msub><m:mi>X</m:mi><m:mi>n</m:mi></m:msub><m:mo>,</m:mo><m:msub><m:mi>D</m:mi><m:mrow><m:mi>n</m:mi><m:mo>+</m:mo><m:mn>1</m:mn></m:mrow></m:msub><m:mo>}</m:mo></m:mrow></m:math> is independent
for each <emphasis effect="italics">n</emphasis>.</para>
    <!--empty paragraphs get left behind.-->
    <para id="id310529">Analyze the system as a Markov decision process with case 3 gains, depending upon
current state, action, and demand.   Determine the transition probability matrix
PA (properly padded) and the gain matrix (also padded).   <emphasis effect="italics">Sample calculations</emphasis> are
as follows:</para>
    <!--empty paragraphs get left behind.-->
    <list id="id310548" display="block" list-type="bulleted"><item id="uid3">State 0, action 0:   <m:math overflow="scroll"><m:mrow><m:msub><m:mi>p</m:mi><m:mn>00</m:mn></m:msub><m:mrow><m:mo>(</m:mo><m:mn>0</m:mn><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mn>1</m:mn></m:mrow></m:math> (all other <m:math overflow="scroll"><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mn>0</m:mn><m:mi>k</m:mi></m:mrow></m:msub><m:mrow><m:mo>(</m:mo><m:mn>0</m:mn><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow></m:math>)
</item>
      <item id="uid4">State 0, action 2:   <m:math overflow="scroll"><m:mrow><m:msub><m:mi>p</m:mi><m:mn>00</m:mn></m:msub><m:mrow><m:mo>(</m:mo><m:mn>2</m:mn><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mi>P</m:mi><m:mrow><m:mo>(</m:mo><m:mi>D</m:mi><m:mo>≥</m:mo><m:mn>2</m:mn><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mn>3</m:mn><m:mo>/</m:mo><m:mn>5</m:mn><m:mo>,</m:mo><m:msub><m:mi>p</m:mi><m:mn>01</m:mn></m:msub><m:mrow><m:mo>(</m:mo><m:mn>2</m:mn><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mi>P</m:mi><m:mrow><m:mo>(</m:mo><m:mi>D</m:mi><m:mo>=</m:mo><m:mn>1</m:mn><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mn>1</m:mn><m:mo>/</m:mo><m:mn>5</m:mn></m:mrow></m:math>, etc.
</item>
      <item id="uid5">State 2, action 2:   <m:math overflow="scroll"><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mn>2</m:mn><m:mi>j</m:mi></m:mrow></m:msub><m:mrow><m:mo>(</m:mo><m:mi>k</m:mi><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mn>1</m:mn><m:mo>/</m:mo><m:mn>5</m:mn><m:mo>,</m:mo><m:mi>k</m:mi><m:mo>=</m:mo><m:mn>0</m:mn><m:mo>,</m:mo><m:mn>1</m:mn><m:mo>,</m:mo><m:mn>2</m:mn><m:mo>,</m:mo><m:mn>3</m:mn><m:mo>,</m:mo><m:mn>4</m:mn></m:mrow></m:math></item>
    </list>
    <para id="id310801">For state = <emphasis effect="italics">i</emphasis>, action = <emphasis effect="italics">a</emphasis>, and demand = <emphasis effect="italics">k</emphasis>,   we seek <m:math overflow="scroll"><m:mrow><m:mi>g</m:mi><m:mo>(</m:mo><m:mi>i</m:mi><m:mo>,</m:mo><m:mi>a</m:mi><m:mo>,</m:mo><m:mi>k</m:mi><m:mo>)</m:mo></m:mrow></m:math></para>
    <!--empty paragraphs get left behind.-->
    <para id="eip-812"><m:math overflow="scroll">
	<m:mtable>
		<m:mtr>
			<m:mtd> 
				<m:mrow><m:mi>g</m:mi><m:mo>(</m:mo><m:mn>0</m:mn><m:mo>,</m:mo><m:mn>0</m:mn><m:mo>,</m:mo><m:mi>k</m:mi><m:mo>)</m:mo><m:mo>=</m:mo><m:mo>-</m:mo><m:mn>40</m:mn><m:mi>k</m:mi></m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>0</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-40</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-80</m:mn>
				</m:mrow>
</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-120</m:mn>
				</m:mrow>
</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-160</m:mn>
				</m:mrow>
			</m:mtd>
		</m:mtr>
		<m:mtr>
			<m:mtd>
				<m:mrow><m:mi>g</m:mi><m:mo>(</m:mo><m:mn>0</m:mn><m:mo>,</m:mo><m:mn>2</m:mn><m:mo>,</m:mo><m:mi>k</m:mi><m:mo>)</m:mo><m:mo>=</m:mo><m:mo>-</m:mo><m:mn>300</m:mn><m:mo>+</m:mo><m:mn>200</m:mn><m:mo movablelimits="true" form="prefix">min</m:mo><m:mo>{</m:mo><m:mi>k</m:mi><m:mo>,</m:mo><m:mn>2</m:mn><m:mo>}</m:mo><m:mo>-</m:mo><m:mn>40</m:mn><m:mo movablelimits="true" form="prefix">max</m:mo><m:mo>{</m:mo><m:mi>k</m:mi><m:mo>-</m:mo><m:mn>2</m:mn><m:mo>,</m:mo><m:mn>0</m:mn><m:mo>}</m:mo></m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-300</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-100</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>100</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>60</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>20</m:mn>
				</m:mrow>
			</m:mtd>
		</m:mtr>
		<m:mtr>
			<m:mtd>
				<m:mrow><m:mi>g</m:mi><m:mo>(</m:mo><m:mn>0</m:mn><m:mo>,</m:mo><m:mn>4</m:mn><m:mo>,</m:mo><m:mi>k</m:mi><m:mo>)</m:mo><m:mo>=</m:mo><m:mo>-</m:mo><m:mn>480</m:mn><m:mo>+</m:mo><m:mn>200</m:mn><m:mi>k</m:mi></m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-480</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-280</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>-80</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>120</m:mn>
				</m:mrow>
			</m:mtd>
			<m:mtd>
				<m:mrow>
					<m:mn>320</m:mn>
				</m:mrow>
			</m:mtd>
		</m:mtr>
	</m:mtable>
</m:math></para>
    <list id="id311039" display="block" list-type="enumerated">
      <item id="uid9">Complete the transition probability table and the gain table.

</item>
      <item id="uid10">Determine an optimum infinite-horizon strategy with no discounting.

</item>
      <item id="uid11">Determine an optimum infinite-horizon strateby with discounting (alpha = 1/1.02).

</item>
      <item id="uid12">The manager decides to set up a six-week strategy, after which new
sales conditions may be established.   Determine an optimum strategy for the six-week period.

</item>
    </list>
    <para id="id311110">
      <emphasis effect="bold">Data file</emphasis>
    </para>
    <!--empty paragraphs get left behind.-->
    <code id="id311120" display="block">% file orderdata.m

    % Version of 4/5/94

    % Data organized for computation

    type = 3;

    states = 0:4;

    A   = [0   2   4 ...                   % Actions (padded)

           0   2  02 ...

           0   2  02 ...

           0  00  00 ...

           0  00  00];

    C   = [0 -300 -480 ...           % Order costs (padded)

           0 -300 -300 ...

           0 -300 -300 ...

           0    0    0 ...

           0    0    0];

    SP = 200;                                   % Selling price

    BP = 40;                                     % Backorder penalty

    PD = 0.2*ones(1,5);               % Demand probabilities
</code>
</example>
    <section id="fs-id1169854778569"><title>Transition Probabilities and Gains</title><para id="id311308">
      <emphasis effect="bold">The procedure</emphasis>
    </para>

    <code id="eip-id1169730283129" display="block"> % file reorder.m
% Version of 4/11/94
% Calculates PA and GA for reorder policy
states = input('Enter row vector of states   ');
A   = input('Enter row vector A of actions (padded)   ');
C   = input('Enter row vector C of order costs (padded)   ');
D   = input('Enter row vector D of demand values   ');
PD = input('Enter row vector PD of demand probabilities     ');
SP = input('Enter unit selling price SP   ');
BP = input('Enter backorder penalty cost BP   ');
m   = length(states');
q   = length(A);
na = q/m;
N   = length(D);
S   = ones(na,1)*states;
S   = S(:)';
[d,s] = meshgrid(D,S);
a   = A'*ones(1,N);
ca = C'*ones(1,N);
TA = (s + a - d).*(s + a - d &gt;= 0);
for i = 1:q
PA(i,:) = tdbn(states,TA(i,:),PD);
end
PA
GA = ca + SP*d - (SP + BP)*(d -s -a).*(d &gt; s+a)
</code>


    <para id="id311742">
      <emphasis effect="bold">The calculations</emphasis>
    </para>
<para id="fs-id7044672"><code id="eip-id4207987" display="block">orderdata
 reorder
Enter row vector of states   states
Enter row vector A of actions (padded)   A
Enter row vector C of order costs (padded)   C
Enter row vector D of demand values   D
Enter row vector PD of demand probabilities     PD
Enter unit selling price SP   SP
Enter backorder penalty cost BP   BP
PA =
      1.0000            0            0            0            0
      0.6000       0.2000       0.2000            0            0
      0.2000       0.2000       0.2000       0.2000       0.2000
      0.8000       0.2000            0            0            0
      0.4000       0.2000       0.2000       0.2000            0
      0.4000       0.2000       0.2000       0.2000            0
      0.6000       0.2000       0.2000            0            0
      0.2000       0.2000       0.2000       0.2000       0.2000
      0.2000       0.2000       0.2000       0.2000       0.2000
      0.4000       0.2000       0.2000       0.2000            0
      0.4000       0.2000       0.2000       0.2000            0
      0.4000       0.2000       0.2000       0.2000            0
      0.2000       0.2000       0.2000       0.2000       0.2000
      0.2000       0.2000       0.2000       0.2000       0.2000
      0.2000       0.2000       0.2000       0.2000       0.2000
GA =
           0          -40          -80         -120         -160
        -300         -100          100           60           20
        -480         -280          -80          120          320
           0          200          160          120           80
        -300         -100          100          300          260
        -300         -100          100          300          260
           0          200          400          360          320
        -300         -100          100          300          500
        -300         -100          100          300          500
           0          200          400          600          560
           0          200          400          600          560
           0          200          400          600          560
           0          200          400          600          800
           0          200          400          600          800
           0          200          400          600          800
    </code>
</para>
</section>

    <section id="fs-id8210286">
      <title>Infinite-horizon strategy (no discounting)</title>
<code id="fs-id4437027" display="block">polit
Data needed:

- - - - - - - - - - - - - - -

Enter type number to show gain type   type
Enter row vector of states   states
Enter row vector A of possible actions   A
Enter value of alpha (= 1 for no discounting)   1
Enter matrix PA of transition probabilities   PA
Enter matrix GA of gains   GA
Enter row vector PD of demand probabilities   PD
Index    Action   Value
    1         0     -80
    2         2     -44
    3         4     -80
    4         0     112
    5         2      52
    6         2      52
    7         0     256
    8         2     100
    9         2     100
   10         0     352
   11         0     352
   12         0     352
   13         0     400
   14         0     400
   15         0     400
Initial policy: action numbers
        2         1         1         1         1
Policy: actions
        2         0         0         0         0

New policy: action numbers
        3         2         2         1         1
Policy: actions
        4         2         2         0         0
Long-run distribution
      0.2800       0.2000       0.2000       0.2000       0.1200
Test values for selecting new policy
      Index         Action   Test Value
      1.0000             0    -248.0000
      2.0000        2.0000    -168.8000
      3.0000        4.0000     -41.6000
      4.0000             0     -48.8000
      5.0000        2.0000      -5.6000
      6.0000        2.0000      -5.6000
      7.0000             0     131.2000
      8.0000        2.0000     138.4000
      9.0000        2.0000     138.4000
     10.0000             0     294.4000
     11.0000             0     294.4000
     12.0000             0     294.4000
     13.0000             0     438.4000
     14.0000             0     438.4000
     15.0000             0     438.4000
    Optimum policy
      State         Action        Value
           0        4.0000    -168.0000
      1.0000        2.0000    -132.0000
      2.0000        2.0000      12.0000
      3.0000             0     168.0000
      4.0000             0     312.0000
Long-run expected gain per period G
  126.4000
    </code>
</section>

    <section id="fs-id4389453">
      <title>Infinite-horizon strategy (with discounting)</title>
<code id="fs-id1167087507307" display="block">polit
Data needed:
- - - - - - - - - - - - - - -
Enter case number to show gain type   type
Enter row vector of states   states
Enter row vector A of possible actions   A
Enter value of alpha (= 1 for no discounting)   1/1.02
Enter matrix PA of transition probabilities   PA
Enter matrix GA of gains   GA
Enter row vector PD of demand probabilities   PD
 Index    Action     Value
     1         0      -80
     2         2      -44
     3         4      -80
     4         0      112
     5         2       52
     6         2       52
     7         0      256
     8         2      100
     9         2      100
     10         0     352
     11         0     352
     12         0     352
     13         0     400
     14         0     400
     15         0     400
Initial policy: action numbers
        2         1         1         1         1
Policy: actions
        2         0         0         0         0
New policy: action numbers
        3         2         2         1         1
Policy: actions
        4         2         2         0         0
Test values for selecting policy
Index         Action     Test Value
1.0e+03 *
0.0010             0         6.0746
0.0020        0.0020         6.1533
0.0030        0.0040         6.2776
0.0040             0         6.2740
0.0050        0.0020         6.3155
0.0060        0.0020         6.3155
0.0070             0         6.4533
0.0080        0.0020         6.4576
0.0090        0.0020         6.4576
0.0100             0         6.6155
0.0110             0         6.6155
0.0120             0         6.6155
0.0130             0         6.7576
0.0140             0         6.7576
0.0150             0         6.7576
Optimum policy
State       Action       Value
1.0e+03 * 
     0       0.0040       6.2776
0.0010       0.0020       6.3155
0.0020       0.0020       6.4576
0.0030            0       6.6155
0.0040            0       6.7576
</code>
</section>
    <section id="fs-id3912571">
      <title>Finite-horizon calculations</title>
    <code id="fs-id1167088575439" display="block">dpinit
Initialize for finite horizon calculations
Matrices A, PA, and GA, padded if necessary
Enter type number to show gain type   type
Enter vector of states   states
Enter row vector A of possible actions   A
Enter matrix PA of transition probabilities   PA
Enter matrix GA of gains   GA
Enter row vector PD of demand probabilities   PD
Call for dprog
dprog
States and expected total gains
      0       1       2       3       4
    -44     112     256     352     400
States   Actions
     0         2
     1         0
     2         0
     3         0
     4         0
dprog
States and expected total gains
         0     1.0000     2.0000     3.0000     4.0000
  135.2000   178.4000   315.2000   478.4000   615.2000
States   Actions
     0         4
     1         2
     2         2
     3         0
     4         0
dprog
States and expected total gains
         0     1.0000     2.0000     3.0000     4.0000
  264.4800   300.4800   444.4800   600.4800   744.4800
States   Actions
     0         4
     1         2
     2         2
     3         0
     4         0
dprog
States and expected total gains
         0     1.0000     2.0000     3.0000     4.0000
  390.8800   426.8800   570.8800   726.8800   870.8800
States   Actions
     0         4
     1         2
     2         2
     3         0
     4         0
 dprog
States and expected total gains
         0     1.0000     2.0000     3.0000     4.0000
  517.2800   553.2800   697.2800   853.2800   997.2800
States   Actions
     0         4
     1         2
     2         2
     3         0
     4         0
dprog
States and expected total gains
    1.0e+03 *
           0       0.0010       0.0020       0.0030       0.0040
      0.6437       0.6797       0.8237       0.9797       1.1237
States   Actions
     0         4
     1         2
     2         2
     3         0
     4         0
</code>
</section>
  </content>
</document>